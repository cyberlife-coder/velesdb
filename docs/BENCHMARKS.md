# ðŸ“Š VelesDB Performance Benchmarks

*Last updated: January 8, 2026 (v0.8.12)*

---

## ðŸš€ v0.8.5 Headline

| Metric | Baseline | VelesDB | Winner |
|--------|----------|---------|--------|
| **SIMD Dot Product (768D)** | 280ns (Naive) | **36ns** | **VelesDB 8x** âœ… |
| **Search (10K)** | ~50ms (pgvector) | **~105Âµs** | **VelesDB 476x** âœ… |
| **Hybrid Search (1K)** | N/A | **62Âµs** | **VelesDB** âœ… |
| **Recall@10** | 100% | **100%** | **VelesDB Perfect** âœ… |

### When to Choose VelesDB

- âœ… **Ultra-low latency** â€” Microsecond-level search on local datasets
- âœ… **Embedded/Desktop** â€” Native Rust integration with zero network overhead
- âœ… **On-Prem/Edge** â€” Single binary, no dependencies
- âœ… **WASM/Browser** â€” Client-side vector search capability

### When to Choose pgvector

- âœ… Existing PostgreSQL infrastructure
- âœ… Need 100% recall

---

## âš¡ SIMD Performance Summary (768D)

| Operation | Latency | Throughput | Speedup |
|-----------|---------|------------|----------|
| **Dot Product** | 36ns | 28M/s | 8x |
| **Euclidean** | 46ns | 22M/s | 6x |
| **Cosine** | 93ns | 11M/s | 3x |
| **Hamming** | 6ns | 164M/s | 34x |
| **Jaccard** | 160ns | 6M/s | 10x |

---

## ðŸ” Hybrid Search Performance

| Scale | Vector+Text | Vector Only | Text Only |
|-------|-------------|-------------|-----------|
| 100 docs | 55Âµs | 54Âµs | 26Âµs |
| 1K docs | 62Âµs | 56Âµs | 30Âµs |

---

## ðŸ” ColumnStore Filtering

| Scale | Throughput | vs JSON |
|-------|------------|----------|
| 100k items | 3.7M/s | **122x faster** |

---

## ðŸ“ VelesQL Parser

| Mode | Latency | Throughput |
|------|---------|------------|
| Parse | 570ns | 1.7M qps |
| **Cache Hit** | **49ns** | **20M qps** |

```rust
use velesdb_core::velesql::QueryCache;
let cache = QueryCache::new(1000);
let query = cache.parse("SELECT * FROM docs LIMIT 10")?;
```

---

## ðŸ“ˆ HNSW Recall Profiles

| Profile | Recall@10 (100K) | Latency P50 | Method |
|---------|------------------|-------------|--------|
| Fast | 34.2% | 59.3ms | HNSW ef=64 |
| Balanced | 48.8% | 60.9ms | HNSW ef=128 |
| Accurate | 67.6% | 78.3ms | HNSW ef=256 |
| **HighRecall** | **96.1%** âœ… | 73.0ms | HNSW ef=1024 |
| **Perfect** | **100%** | 42.1ms | HNSW ef=2048 |

> **Note**: Recall@10 â‰¥95% garantie pour HighRecall et Perfect modes.

---

## ðŸš€ Parallel Performance

| Operation | Speedup (8 cores) |
|-----------|------------------|
| Batch Search | **19x** |
| Batch Insert | **18x** |

---

## ðŸŽ¯ Performance Targets by Scale

| Dataset Size | Search P99 | Recall@10 | Status |
|--------------|------------|-----------|--------|
| 10K vectors | **<1ms** | â‰¥98% | âœ… Achieved |
| 100K vectors | **<5ms** | â‰¥95% | âœ… Achieved (96.1%) |
| 1M vectors | **<50ms** | â‰¥95% | ðŸŽ¯ Target |

> Use `HnswParams::for_dataset_size()` for automatic parameter tuning.

---

## ðŸ†• v0.8.12 Native HNSW Implementation

VelesDB now includes a **custom Native HNSW implementation** based on 2024-2026 research papers (Flash Method, VSAG Framework).

### Native vs hnsw_rs Comparison

*Benchmarked January 8, 2026 â€” 5,000 vectors, 128D, Euclidean distance*

| Operation | Native HNSW | hnsw_rs | Improvement |
|-----------|-------------|---------|-------------|
| **Search (100 queries)** | 26.9 ms | 32.4 ms | **1.2x faster** âœ… |
| **Parallel Insert (5k)** | 1.47 s | 1.57 s | **1.07x faster** âœ… |
| **Recall** | ~99% | baseline | Parity âœ“ |

### Why Native HNSW?

- **No external dependency** â€” Full control over graph construction and search
- **SIMD-optimized distances** â€” Custom AVX2/SSE implementations
- **Lock-free reads** â€” Concurrent search without blocking
- **Future-ready** â€” Foundation for int8 quantized graph traversal

```bash
# Enable Native HNSW
cargo build --features native-hnsw

# Run comparison benchmark
cargo bench --bench hnsw_comparison_benchmark
```

ðŸ“– Full guide: [docs/reference/NATIVE_HNSW.md](reference/NATIVE_HNSW.md)

---

## ðŸ”¥ v0.8.5 Optimizations

- **Unified VelesQL execution** â€” `Collection::execute_query()` for all components
- **Batch search with filters** â€” Individual filters per query in batch operations
- **Buffer reuse** â€” Thread-local buffer for brute-force search (~40% allocation reduction)
- **Adaptive HNSW params** â€” `for_dataset_size()` and `million_scale()` APIs
- **32-wide SIMD unrolling** â€” 4x f32x8 accumulators for maximum ILP
- **Pre-normalized functions** â€” `cosine_similarity_normalized()` ~40% faster
- **SIMD-accelerated HNSW** â€” AVX2/SSE via `wide` crate
- **Parallel insertion** â€” Rayon-based graph construction
- **CPU prefetch hints** â€” L2 cache warming
- **GPU acceleration** â€” [Roadmap](GPU_ACCELERATION_ROADMAP.md) for batch operations

---

## ðŸ§ª Methodology

- **Hardware**: 8-core CPU, 32GB RAM
- **Environment**: Rust 1.83, `--release`, `target-cpu=native`
- **Framework**: Criterion.rs
