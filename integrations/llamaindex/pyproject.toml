[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "llama-index-vector-stores-velesdb"
version = "1.3.0"
description = "LlamaIndex VectorStore for VelesDB: The Local AI Memory Database. Microsecond RAG retrieval."
readme = "README.md"
license = "MIT"
requires-python = ">=3.9"
authors = [
    { name = "VelesDB Team", email = "contact@wiscale.fr" }
]
keywords = ["velesdb", "llamaindex", "vector-store", "embeddings", "rag", "local-first", "ai-memory", "semantic-search", "llm", "gpt"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]

dependencies = [
    "llama-index-core>=0.10.0",
    "velesdb>=0.8.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0",
    "pytest-asyncio>=0.21",
]

[project.urls]
Homepage = "https://github.com/cyberlife-coder/VelesDB"
Documentation = "https://github.com/cyberlife-coder/VelesDB#readme"

[tool.hatch.build.targets.wheel]
packages = ["src/llamaindex_velesdb"]
